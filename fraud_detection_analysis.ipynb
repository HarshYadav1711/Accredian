{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection in Financial Transactions\n",
    "\n",
    "**Author**: Data Science Intern Candidate  \n",
    "**Date**: February 2026  \n",
    "**Dataset**: PaySim Synthetic Financial Dataset (~6.3M transactions)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Understanding\n",
    "\n",
    "### What is Fraud Detection?\n",
    "\n",
    "Fraud detection in financial services means identifying transactions that are **unauthorized, deceptive, or illegal**. In this context, we're looking at mobile money transactions where criminals may:\n",
    "\n",
    "- Take over customer accounts\n",
    "- Transfer funds to accounts they control\n",
    "- Cash out before the fraud is discovered\n",
    "\n",
    "### Why Does This Matter for Businesses?\n",
    "\n",
    "| Impact Area | Consequence |\n",
    "|-------------|-------------|\n",
    "| **Financial Loss** | Direct monetary loss from fraudulent transactions |\n",
    "| **Customer Trust** | Victims may leave the platform permanently |\n",
    "| **Regulatory Risk** | Fines and penalties for inadequate fraud controls |\n",
    "| **Operational Cost** | Manual investigation of suspected fraud is expensive |\n",
    "\n",
    "### What Does Success Look Like?\n",
    "\n",
    "Success is **not** just high accuracy. In fraud detection, we need to:\n",
    "\n",
    "1. **Catch most fraudulent transactions** (high recall) â€” missing fraud costs money\n",
    "2. **Minimize false alarms** (reasonable precision) â€” blocking legitimate customers hurts business\n",
    "3. **Provide actionable insights** â€” understanding *why* transactions are flagged helps improve controls\n",
    "\n",
    "The business goal is to **reduce fraud losses while maintaining customer experience**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview & Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, roc_curve, precision_recall_curve)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with memory-efficient dtypes\n",
    "dtype_spec = {\n",
    "    'step': 'int16',\n",
    "    'type': 'category',\n",
    "    'amount': 'float32',\n",
    "    'nameOrig': 'object',\n",
    "    'oldbalanceOrg': 'float32',\n",
    "    'newbalanceOrig': 'float32',\n",
    "    'nameDest': 'object',\n",
    "    'oldbalanceDest': 'float32',\n",
    "    'newbalanceDest': 'float32',\n",
    "    'isFraud': 'int8',\n",
    "    'isFlaggedFraud': 'int8'\n",
    "}\n",
    "\n",
    "df = pd.read_csv('Fraud.csv', dtype=dtype_spec)\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} transactions, {df.shape[1]} features\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview\n",
    "print(\"=\" * 50)\n",
    "print(\"DATASET STRUCTURE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTime span: {df['step'].max()} hours ({df['step'].max() // 24} days)\")\n",
    "print(f\"\\nTransaction types: {df['type'].unique().tolist()}\")\n",
    "print(f\"\\nFeatures:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class imbalance analysis\n",
    "fraud_counts = df['isFraud'].value_counts()\n",
    "fraud_pct = df['isFraud'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"CLASS DISTRIBUTION (Target Variable: isFraud)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nLegitimate transactions: {fraud_counts[0]:,} ({fraud_pct[0]:.2f}%)\")\n",
    "print(f\"Fraudulent transactions: {fraud_counts[1]:,} ({fraud_pct[1]:.2f}%)\")\n",
    "print(f\"\\nImbalance ratio: 1 fraud per {fraud_counts[0] // fraud_counts[1]:,} legitimate transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class imbalance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Bar chart\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[0].bar(['Legitimate', 'Fraud'], fraud_counts.values, color=colors)\n",
    "axes[0].set_ylabel('Number of Transactions')\n",
    "axes[0].set_title('Transaction Count by Class')\n",
    "for i, v in enumerate(fraud_counts.values):\n",
    "    axes[0].text(i, v + 50000, f'{v:,}', ha='center', fontsize=10)\n",
    "\n",
    "# Pie chart (zoomed to show fraud)\n",
    "axes[1].pie([fraud_pct[1], fraud_pct[0]], labels=['Fraud', 'Legitimate'], \n",
    "            colors=['#e74c3c', '#2ecc71'], autopct='%.2f%%', startangle=90,\n",
    "            explode=[0.1, 0])\n",
    "axes[1].set_title('Fraud Percentage (Highly Imbalanced)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key observation: Which transaction types have fraud?\n",
    "fraud_by_type = df.groupby('type').agg(\n",
    "    total=('isFraud', 'count'),\n",
    "    fraud_count=('isFraud', 'sum')\n",
    ").reset_index()\n",
    "fraud_by_type['fraud_rate'] = (fraud_by_type['fraud_count'] / fraud_by_type['total'] * 100).round(2)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"FRAUD DISTRIBUTION BY TRANSACTION TYPE\")\n",
    "print(\"=\" * 50)\n",
    "print(fraud_by_type.to_string(index=False))\n",
    "print(\"\\nðŸ’¡ KEY INSIGHT: Fraud ONLY occurs in TRANSFER and CASH_OUT transactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Observations\n",
    "\n",
    "1. **Severe class imbalance**: Fraud represents only ~0.13% of all transactions\n",
    "2. **Fraud is concentrated**: Only TRANSFER and CASH_OUT transactions contain fraud\n",
    "3. **This matches the fraud pattern**: Criminals transfer money, then cash out\n",
    "\n",
    "**Implication**: We should focus our analysis on TRANSFER and CASH_OUT transactions, and use techniques like SMOTE to handle imbalance during modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\" * 50)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "missing = df.isnull().sum()\n",
    "print(f\"\\n{missing[missing > 0] if missing.sum() > 0 else 'No missing values found!'}\")\n",
    "\n",
    "# Check for zero balances in destination (expected for merchants)\n",
    "merchant_dest = df[df['nameDest'].str.startswith('M')]\n",
    "print(f\"\\nMerchant destinations: {len(merchant_dest):,} transactions\")\n",
    "print(f\"Merchants with zero balances: {(merchant_dest['oldbalanceDest'] == 0).sum():,}\")\n",
    "print(\"\\nðŸ“ Note: Merchant (M) destinations have no balance info by design.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on fraud-relevant transactions only\n",
    "df_relevant = df[df['type'].isin(['TRANSFER', 'CASH_OUT'])].copy()\n",
    "print(f\"Filtered to TRANSFER and CASH_OUT: {len(df_relevant):,} transactions\")\n",
    "print(f\"Fraud cases retained: {df_relevant['isFraud'].sum():,} (100% of all fraud)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "print(\"=\" * 50)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Balance change for origin account\n",
    "df_relevant['orig_balance_change'] = df_relevant['newbalanceOrig'] - df_relevant['oldbalanceOrg']\n",
    "\n",
    "# 2. Balance change for destination account  \n",
    "df_relevant['dest_balance_change'] = df_relevant['newbalanceDest'] - df_relevant['oldbalanceDest']\n",
    "\n",
    "# 3. Error in origin balance (amount doesn't match balance change)\n",
    "df_relevant['orig_balance_error'] = (df_relevant['oldbalanceOrg'] - df_relevant['amount'] - df_relevant['newbalanceOrig']).abs()\n",
    "\n",
    "# 4. Error in destination balance\n",
    "df_relevant['dest_balance_error'] = (df_relevant['oldbalanceDest'] + df_relevant['amount'] - df_relevant['newbalanceDest']).abs()\n",
    "\n",
    "# 5. Is the origin account being emptied?\n",
    "df_relevant['is_orig_emptied'] = ((df_relevant['oldbalanceOrg'] > 0) & \n",
    "                                   (df_relevant['newbalanceOrig'] == 0)).astype(int)\n",
    "\n",
    "# 6. Hour of day (for time patterns)\n",
    "df_relevant['hour'] = df_relevant['step'] % 24\n",
    "\n",
    "# 7. Transaction type as binary\n",
    "df_relevant['is_transfer'] = (df_relevant['type'] == 'TRANSFER').astype(int)\n",
    "\n",
    "print(\"Created features:\")\n",
    "print(\"  â€¢ orig_balance_change: Change in sender's balance\")\n",
    "print(\"  â€¢ dest_balance_change: Change in receiver's balance\")\n",
    "print(\"  â€¢ orig_balance_error: Discrepancy in sender's balance calculation\")\n",
    "print(\"  â€¢ dest_balance_error: Discrepancy in receiver's balance calculation\")\n",
    "print(\"  â€¢ is_orig_emptied: Flag if account was emptied to zero\")\n",
    "print(\"  â€¢ hour: Hour of day (0-23)\")\n",
    "print(\"  â€¢ is_transfer: Binary flag for TRANSFER type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier analysis (outliers may indicate fraud!)\n",
    "print(\"=\" * 50)\n",
    "print(\"OUTLIER ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compare amount distributions\n",
    "print(\"\\nAmount statistics by fraud status:\")\n",
    "print(df_relevant.groupby('isFraud')['amount'].describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize amount distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Log-transformed amount distribution\n",
    "for label, color in [(0, '#2ecc71'), (1, '#e74c3c')]:\n",
    "    subset = df_relevant[df_relevant['isFraud'] == label]['amount']\n",
    "    axes[0].hist(np.log10(subset + 1), bins=50, alpha=0.6, \n",
    "                 label='Fraud' if label else 'Legitimate', color=color)\n",
    "axes[0].set_xlabel('Log10(Amount + 1)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Transaction Amount Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Boxplot comparison\n",
    "df_relevant.boxplot(column='amount', by='isFraud', ax=axes[1])\n",
    "axes[1].set_title('Amount by Fraud Status')\n",
    "axes[1].set_xlabel('Is Fraud')\n",
    "axes[1].set_ylabel('Amount')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ KEY INSIGHT: Fraudulent transactions tend to have HIGHER amounts.\")\n",
    "print(\"   This makes sense - criminals want to maximize their take per transaction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "print(\"=\" * 50)\n",
    "print(\"CORRELATION WITH FRAUD\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "numeric_cols = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', \n",
    "                'newbalanceDest', 'orig_balance_change', 'dest_balance_change',\n",
    "                'orig_balance_error', 'dest_balance_error', 'is_orig_emptied', \n",
    "                'hour', 'is_transfer', 'isFraud']\n",
    "\n",
    "corr_with_fraud = df_relevant[numeric_cols].corr()['isFraud'].drop('isFraud').sort_values(key=abs, ascending=False)\n",
    "print(\"\\nCorrelation with isFraud (sorted by absolute value):\")\n",
    "print(corr_with_fraud.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr_matrix = df_relevant[numeric_cols].corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Summary\n",
    "\n",
    "**What we did:**\n",
    "1. âœ… No missing values in the dataset\n",
    "2. âœ… Filtered to fraud-relevant transactions (TRANSFER, CASH_OUT)\n",
    "3. âœ… Created domain-relevant features (balance errors, account emptying flag)\n",
    "4. âœ… Retained outliers â€” they may indicate fraud behavior\n",
    "\n",
    "**Key findings:**\n",
    "- `is_orig_emptied` has strong correlation with fraud (accounts being emptied)\n",
    "- Balance errors may indicate suspicious activity\n",
    "- Higher transaction amounts correlate with fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection & Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "print(\"=\" * 50)\n",
    "print(\"FEATURE SELECTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Features to use\n",
    "features = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', \n",
    "            'newbalanceDest', 'orig_balance_error', 'dest_balance_error',\n",
    "            'is_orig_emptied', 'hour', 'is_transfer']\n",
    "\n",
    "print(\"\\nSelected features and rationale:\")\n",
    "print(\"-\" * 50)\n",
    "feature_rationale = {\n",
    "    'amount': 'Fraud tends to involve larger amounts',\n",
    "    'oldbalanceOrg': 'Fraudsters often target accounts with funds',\n",
    "    'newbalanceOrig': 'Fraud often empties accounts completely',\n",
    "    'oldbalanceDest': 'Destination patterns may differ for fraud',\n",
    "    'newbalanceDest': 'Receiving account behavior after transaction',\n",
    "    'orig_balance_error': 'Calculation discrepancies may indicate tampering',\n",
    "    'dest_balance_error': 'Unusual destination balance changes',\n",
    "    'is_orig_emptied': 'Strong fraud signal - account drained to zero',\n",
    "    'hour': 'Fraud may occur at specific times',\n",
    "    'is_transfer': 'Transfer vs cash-out fraud patterns differ'\n",
    "}\n",
    "\n",
    "for feat, reason in feature_rationale.items():\n",
    "    print(f\"  â€¢ {feat}: {reason}\")\n",
    "\n",
    "print(\"\\nâŒ Excluded features:\")\n",
    "print(\"  â€¢ nameOrig, nameDest: Customer IDs - not generalizable\")\n",
    "print(\"  â€¢ step: Raw time step - hour captures cyclical patterns\")\n",
    "print(\"  â€¢ type: Encoded as is_transfer\")\n",
    "print(\"  â€¢ isFlaggedFraud: Would leak information (based on >200K rule)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final dataset\n",
    "X = df_relevant[features].copy()\n",
    "y = df_relevant['isFraud'].copy()\n",
    "\n",
    "print(f\"\\nFinal dataset: {X.shape[0]:,} samples, {X.shape[1]} features\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Selection & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (stratified to preserve fraud ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTraining set: {len(X_train):,} samples\")\n",
    "print(f\"  - Legitimate: {(y_train == 0).sum():,}\")\n",
    "print(f\"  - Fraud: {(y_train == 1).sum():,}\")\n",
    "print(f\"\\nTest set: {len(X_test):,} samples\")\n",
    "print(f\"  - Legitimate: {(y_test == 0).sum():,}\")\n",
    "print(f\"  - Fraud: {(y_test == 1).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance with SMOTE (on training set only!)\n",
    "print(\"=\" * 50)\n",
    "print(\"HANDLING CLASS IMBALANCE WITH SMOTE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBefore SMOTE: {len(X_train):,} samples\")\n",
    "print(f\"After SMOTE: {len(X_train_balanced):,} samples\")\n",
    "print(f\"\\nBalanced class distribution: {pd.Series(y_train_balanced).value_counts().to_dict()}\")\n",
    "print(\"\\nðŸ“ Note: SMOTE creates synthetic minority samples to balance classes.\")\n",
    "print(\"   Applied only to training data to avoid data leakage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Features scaled using StandardScaler.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Logistic Regression (Interpretable Baseline)\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL 1: LOGISTIC REGRESSION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nWhy Logistic Regression?\")\n",
    "print(\"  â€¢ Interpretable coefficients show feature importance\")\n",
    "print(\"  â€¢ Fast training even on large datasets\")\n",
    "print(\"  â€¢ Good baseline for comparison\")\n",
    "print(\"  â€¢ Outputs probabilities for risk scoring\")\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train_balanced)\n",
    "print(\"\\nâœ… Logistic Regression trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Random Forest (Non-linear)\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL 2: RANDOM FOREST\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nWhy Random Forest?\")\n",
    "print(\"  â€¢ Captures non-linear relationships\")\n",
    "print(\"  â€¢ Robust to outliers (important for fraud)\")\n",
    "print(\"  â€¢ Built-in feature importance\")\n",
    "print(\"  â€¢ Handles imbalanced data well with class_weight\")\n",
    "\n",
    "# Using original training data with class_weight instead of SMOTE\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"\\nâœ… Random Forest trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "lr_proba = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_proba = rf_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(name, y_true, y_pred, y_proba):\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"{name} EVALUATION\")\n",
    "    print('=' * 50)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Legitimate', 'Fraud']))\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "lr_auc = evaluate_model(\"LOGISTIC REGRESSION\", y_test, lr_pred, lr_proba)\n",
    "rf_auc = evaluate_model(\"RANDOM FOREST\", y_test, rf_pred, rf_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, (name, pred) in zip(axes, [('Logistic Regression', lr_pred), ('Random Forest', rf_pred)]):\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=',d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Predicted Legitimate', 'Predicted Fraud'],\n",
    "                yticklabels=['Actual Legitimate', 'Actual Fraud'])\n",
    "    ax.set_title(f'{name} Confusion Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, proba, auc in [('Logistic Regression', lr_proba, lr_auc), \n",
    "                          ('Random Forest', rf_proba, rf_auc)]:\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Accuracy is Misleading\n",
    "\n",
    "With 99.87% legitimate transactions, a model that predicts **everything as legitimate** would achieve:\n",
    "- **Accuracy**: 99.87% (looks great!)\n",
    "- **Fraud Detection**: 0% (completely useless!)\n",
    "\n",
    "**Business Cost Analysis:**\n",
    "\n",
    "| Error Type | What Happens | Business Impact |\n",
    "|------------|--------------|------------------|\n",
    "| **False Negative** (Missed Fraud) | Fraud gets through | Direct financial loss |\n",
    "| **False Positive** (False Alarm) | Legitimate blocked | Customer frustration, churn |\n",
    "\n",
    "In fraud detection, **False Negatives are usually more costly** because:\n",
    "- Each missed fraud = direct monetary loss\n",
    "- Criminals learn which patterns work\n",
    "- Regulatory penalties for inadequate controls\n",
    "\n",
    "**This is why we prioritize Recall (catching fraud) while maintaining reasonable Precision (not annoying customers).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Fraud Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "print(\"=\" * 50)\n",
    "print(\"FEATURE IMPORTANCE (Random Forest)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop fraud predictors:\")\n",
    "print(importance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(importance_df)))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Feature Importance for Fraud Detection')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression coefficients (interpretability)\n",
    "print(\"=\" * 50)\n",
    "print(\"LOGISTIC REGRESSION COEFFICIENTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coefficient': lr_model.coef_[0]\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nInterpretation: Positive = increases fraud probability\")\n",
    "print(coef_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Fraud Indicators Explained\n",
    "\n",
    "Based on our analysis, the **strongest fraud indicators** are:\n",
    "\n",
    "| Indicator | What It Means | Why It Makes Sense |\n",
    "|-----------|---------------|--------------------|\n",
    "| **Account Emptying** | Origin account balance goes to zero | Fraudsters want to take everything |\n",
    "| **High Transaction Amount** | Larger than typical transactions | Maximize gains per attempt |\n",
    "| **Balance Discrepancies** | Math doesn't add up | Possible record manipulation |\n",
    "| **Destination Balance Patterns** | Unusual receiving account behavior | Money mule accounts may show patterns |\n",
    "\n",
    "**Behavioral Pattern of Fraud:**\n",
    "1. Fraudster gains access to victim's account\n",
    "2. Transfers maximum available balance\n",
    "3. Destination account (often a mule) cashes out quickly\n",
    "\n",
    "This is exactly what the model learned to detect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Business & Prevention Strategy\n",
    "\n",
    "### Recommended Fraud Prevention Framework\n",
    "\n",
    "Based on our findings, here's a practical prevention strategy:\n",
    "\n",
    "#### 1. Real-Time Transaction Monitoring\n",
    "\n",
    "**High-Risk Triggers** (require additional verification):\n",
    "- Transaction would empty the account (balance â†’ 0)\n",
    "- Amount exceeds 90th percentile of customer's history\n",
    "- First-time transfer to new destination\n",
    "- Multiple large transfers in short period\n",
    "\n",
    "#### 2. Risk-Based Authentication\n",
    "\n",
    "| Risk Score | Amount Threshold | Action |\n",
    "|------------|------------------|--------|\n",
    "| Low (0-0.3) | Any | Allow immediately |\n",
    "| Medium (0.3-0.7) | >$10,000 | SMS/Email confirmation |\n",
    "| High (0.7-0.9) | Any | Phone verification |\n",
    "| Very High (>0.9) | Any | Manual review + temporary hold |\n",
    "\n",
    "#### 3. Adaptive Rules Using Model Output\n",
    "\n",
    "```\n",
    "IF model_fraud_probability > 0.8:\n",
    "    BLOCK transaction\n",
    "    ALERT fraud team\n",
    "    NOTIFY customer\n",
    "ELIF model_fraud_probability > 0.5:\n",
    "    HOLD for 15 minutes\n",
    "    REQUEST secondary authentication\n",
    "ELIF account_being_emptied AND destination_is_new:\n",
    "    REQUEST confirmation\n",
    "ELSE:\n",
    "    ALLOW transaction\n",
    "```\n",
    "\n",
    "#### 4. Customer Education\n",
    "- Alerts for unusual account activity\n",
    "- Regular reminders about security practices\n",
    "- Easy fraud reporting mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Measuring Success of Prevention\n",
    "\n",
    "### Key Performance Indicators (KPIs)\n",
    "\n",
    "| Metric | Formula | Target | Why It Matters |\n",
    "|--------|---------|--------|----------------|\n",
    "| **Fraud Rate** | Fraud $ / Total $ | Decrease 50%+ | Primary success metric |\n",
    "| **Detection Rate** | Caught Fraud / Total Fraud | >90% | Model effectiveness |\n",
    "| **False Positive Rate** | False Blocks / Total Blocks | <5% | Customer experience |\n",
    "| **Investigation Efficiency** | True Fraud / Investigated Cases | >30% | Analyst productivity |\n",
    "| **Mean Time to Detect** | Time from fraud to alert | <1 hour | Response speed |\n",
    "\n",
    "### Monitoring Framework\n",
    "\n",
    "**Daily:**\n",
    "- Transaction volumes by risk category\n",
    "- Blocked transaction count and reasons\n",
    "- False positive complaints\n",
    "\n",
    "**Weekly:**\n",
    "- Model performance metrics (precision, recall, AUC)\n",
    "- New fraud pattern identification\n",
    "- Rule effectiveness review\n",
    "\n",
    "**Monthly:**\n",
    "- Total fraud losses vs. baseline\n",
    "- Customer satisfaction scores\n",
    "- Model drift analysis\n",
    "- A/B test results for rule changes\n",
    "\n",
    "### Validating System Improvements\n",
    "\n",
    "1. **A/B Testing**: Route 5% of traffic through new rules, compare outcomes\n",
    "2. **Backtesting**: Apply new model to historical data, measure improvement\n",
    "3. **Champion-Challenger**: Run new model alongside production model\n",
    "4. **Feedback Loop**: Analyst decisions feed back into model retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion & Next Steps\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Fraud is rare but concentrated**: Only 0.13% of transactions are fraudulent, and they only occur in TRANSFER and CASH_OUT types\n",
    "\n",
    "2. **Clear behavioral patterns exist**: Fraudsters tend to empty accounts completely and transfer larger amounts\n",
    "\n",
    "3. **Simple models work well**: Random Forest achieved strong ROC-AUC, and Logistic Regression provides interpretable insights\n",
    "\n",
    "4. **Feature engineering matters**: Domain-relevant features like `is_orig_emptied` and balance errors significantly improve detection\n",
    "\n",
    "### Model Limitations\n",
    "\n",
    "| Limitation | Impact | Mitigation |\n",
    "|------------|--------|------------|\n",
    "| Synthetic data | May not capture all real fraud patterns | Validate on real data before deployment |\n",
    "| No temporal features | Can't detect velocity patterns | Add transaction frequency features |\n",
    "| Static model | Won't adapt to new fraud tactics | Implement regular retraining pipeline |\n",
    "| No customer history | Missing behavioral baselines | Integrate customer profiling |\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "**With More Time:**\n",
    "- Add customer transaction history features\n",
    "- Implement network analysis (related accounts)\n",
    "- Build velocity-based features (transactions per hour/day)\n",
    "- Test gradient boosting models (XGBoost, LightGBM)\n",
    "\n",
    "**For Production:**\n",
    "- Build real-time scoring API\n",
    "- Implement model monitoring and drift detection\n",
    "- Create analyst review dashboard\n",
    "- Set up automated retraining pipeline\n",
    "\n",
    "---\n",
    "\n",
    "**Final Note**: This analysis demonstrates that effective fraud detection requires not just technical modeling skills, but also domain understanding and clear business communication. The goal is not the most complex model, but the most *useful* one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDataset: {len(df):,} total transactions\")\n",
    "print(f\"Analysis subset: {len(df_relevant):,} (TRANSFER + CASH_OUT)\")\n",
    "print(f\"Fraud cases: {y.sum():,} ({y.mean()*100:.2f}%)\")\n",
    "print(f\"\\nModels trained:\")\n",
    "print(f\"  â€¢ Logistic Regression - ROC-AUC: {lr_auc:.4f}\")\n",
    "print(f\"  â€¢ Random Forest - ROC-AUC: {rf_auc:.4f}\")\n",
    "print(f\"\\nTop fraud indicators: {importance_df['Feature'].head(3).tolist()}\")\n",
    "print(\"\\nâœ… Analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
